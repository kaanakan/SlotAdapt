<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script src="https://code.jquery.com/jquery-3.6.4.min.js"></script>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap"
      rel="stylesheet">
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen"/>

<html lang="en">
<head>
	<title>Slot-Guided Adaptation of Pre-trained Diffusion Models for Object-Centric Learning and Compositional Generation</title>
	<meta property="og:image" content="Path to my teaser.jpg"/>
	<meta property="og:title" content="SlotAdapt" />
	<meta property="og:description" content="SlotAdapt" />
    <meta property="twitter:card"          content="SlotAdapt" />
    <meta property="twitter:title"         content="SlotAdapt" />
    <meta property="twitter:description"   content="SlotAdapt" />
    <meta property="twitter:image"         content="Path to my teaser.jpg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Add your Google Analytics tag here -->
    <script async
            src="https://www.googletagmanager.com/gtag/js?id=UA-97476543-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'UA-97476543-1');
    </script>

</head>

<body>
<div class="container">
    <div class="title">
      Slot-Guided Adaptation of Pre-trained Diffusion Models for Object-Centric Learning and Compositional Generation
    </div>


    <br><br>
    <div class="author">
        <a href="https://github.com/kaanakan" target="_blank">Adil Kaan Akan</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://mysite.ku.edu.tr/yyemez/" target="_blank">Yücel Yemez</a><sup>1, 2</sup>
    </div>

    <br><br>
    <div class="affiliation"><sup>1&nbsp;</sup><a href="https://cs.ku.edu.tr" target="_blank">Department of Computer Engineering, Koc University</a></div>
    <div class="affiliation"><sup>2&nbsp;</sup><a href="https://ai.ku.edu.tr" target="_blank">KUIS AI Center</a></div>

    
    <div class="venue">
      ICLR 2025
    </div>
    <br><br>

 
    <div class="links">Paper <a href="https://arxiv.org/abs/2501.15878" target="_blank"> [Arxiv]</a></div>
    <div class="links">Code <a href="" target="_blank"> [GitHub]</a></div>
    <div class="links">Cite <a href="./resources/bibtex.txt" target="_blank"> [BibTeX]</a></div>

    <br>
    <br>
    <br>

    <div class="box" style="height: 60px; padding: 15px; border: 1px solid black;">
      <b><FONT COLOR="RED">TL;DR</FONT></b> 
      We introduce <b>SlotAdapt</b>, a method combining slot attention with pretrained diffusion models for object-centric learning, achieving state-of-the-art performance in object discovery and compositional generation without external supervision.
    </div>

    <br>
    <hr>

    <img style="width: 80%;" src="./resources/pipeline.png"
         alt="Method overview figure"/>
    <br><br>
    <p style="width: 80%;">
      We extract object-centric information from the input image using a visual backbone, which combines DINO and slot attention. Stable Diffusion VAE is used to encode the image into latent space and then noise is added to the latent. Diffusion process is conditioned on the generated slots as well as the register token which is generated by (mean) pooling the slots. We use the original cross attention layers of diffusion model to condition on the register token, and additional adapter attentions to condition on the learned slots. The overall objective is to predict the noise added to the image. Additionally, we introduce a guidance loss between the slot attention masks and adapter cross attention masks, which encourages the similarity between them. The guidance is only applied in the third upsampling block, while slot conditioning is applied throughout all downsampling and upsampling blocks.
    </p>
    <br>

    <!-- <div class="box"><b> <FONT COLOR="RED">TL;DR</FONT></b> we introduce <b>SOLV</b> (Self-supervised Object Centric Learning for Videos), a self-supervised model capable of discovering multiple objects in real-world video sequences without using additional modalities. </div> -->
    <hr>
    
    


    <h1>Abstract</h1>
    <p style="width: 80%;">
      We present SlotAdapt, an object-centric learning method that combines slot attention with pretrained diffusion models by introducing adapters for slot-based conditioning. Our method preserves the generative power of pretrained diffusion models, while avoiding their text-centric conditioning bias. We also incorporate an additional guidance loss into our architecture  to align cross-attention from adapter layers with slot attention. This enhances the alignment of our model with the objects in the input image without using external supervision. Experimental results show that our method outperforms state-of-the-art techniques in object discovery and image generation tasks across multiple datasets, including those with real images. Furthermore, we demonstrate through experiments that our method performs remarkably well on complex real-world images for compositional generation, in contrast to other slot-based generative methods in the literature.
    </p>

    <br><br>

    <hr>

    <h1>Quantitative Results</h1>


    <div class="row">
      <img class="img-center" style="width: 80%;margin: auto;" src="./resources/coco_voc_table.png" alt="COCO-VOC SOTA"/><br><br>
    </div>

    <br>

    <div class="row_v2">
      <p style="width: 80%;">
        <b>Quantitative Results on Pascal VOC and COCO dataset</b> This tables show results in comparison to the previous work in terms of FG-ARI and mBO for instance and semantic segmentation tasks.
      </p>

    </div>

    <br>

    <hr>


    <h1>Qualitative Results</h1>

    <div class="row">
      <div class="column">
        <!-- First Image and Caption -->
        <div class="cropped_v2">
          <img style="width: 100%;" src="./resources/seg.jpeg" />
        </div>
        <p style="text-align: center; font-size: 14px; margin-top: 5px;">
          <b>Segmentation</b> We show visualizations of predicted segments on COCO (left) and VOC (right). SlotAdapt successfully binds distinct instances belonging to the same class.
        </p>
        <hr>
        
        <!-- Second Image and Caption -->
        <div class="cropped_v2">
          <img style="width: 100%;" src="./resources/gen.jpeg" />
        </div>
        <p style="text-align: center; font-size: 14px; margin-top: 5px;">
          <b>Generation</b> We show sample images reconstructed by SlotAdapt conditioned on slots on COCO (left) and VOC (right). SlotAdapt generates reconstructions highly faithful to the original input images.
        </p>
        <hr>
        
        <!-- Third Image and Caption -->
        <div class="cropped_v2">
          <img style="width: 100%;" src="./resources/comp_gen.jpeg" />
        </div>
        <p style="text-align: center; font-size: 14px; margin-top: 5px;">
          <b>Compositional Editing</b> We demonstrate object removal, replacement, and addition edits on COCO images by using slots. Removing highlighted slots (top row) yields realistic and successful generations (first 4 examples). Replacing highlighted objects in the 3rd and 4th images with the cow object from the 5th and 6th images results in highly accurate edits, yet with small changes in the original images. Finally, adding the cow (5th image) and the person (3rd image) slots to the last two images, respectively, generates meaningful examples of complex scenes.
        </p>
        <hr>
      </div>
    </div>
    

    <h1>Paper</h1>

    <div class="paper-info" style="width: 80%;">
      <h3>Slot-Guided Adaptation of Pre-trained Diffusion Models for Object-Centric Learning and Compositional Generation</h3>
      <p>Adil Kaan Akan and Yücel Yemez</p>
      <p>ICLR 2025</p>
      <pre><code>@InProceedings{Akan2025ICLR,
        author = {Akan, Adil Kaan and Yemez, Y\"{u}cel},
        title = {Slot-Guided Adaptation of Pre-trained Diffusion Models for Object-Centric Learning and Compositional Generation},
        booktitle = {International Conference on Learning Representations},
        year      = {2025}}
      </code></pre>
    </div>
    
    <br><br>

</div>

</body>

</html>
